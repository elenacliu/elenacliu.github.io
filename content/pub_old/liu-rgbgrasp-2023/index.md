---
title: 'RGBGrasp: Image-based Object Grasping by Capturing Multiple Views during Robot
  Arm Movement with Neural Radiance Fields'
authors:
- admin
- Kejian Shi
- Kaichen Zhou
- Haoxiao Wang
- Jiyao Zhang
- Hao Dong
author_notes:
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
date: '2023-11-01'
publishDate: '2023-11-29T03:05:44.649463Z'
publication_types:
- manuscript
publication: '*arXiv*'
abstract: 'Robotic research encounters a significant hurdle when it comes to the intricate
  task of grasping objects that come in various shapes, materials, and textures. Unlike
  many prior investigations that heavily leaned on specialized point-cloud cameras
  or abundant RGB visual data to gather 3D insights for object-grasping missions,
  this paper introduces a pioneering approach called RGBGrasp. This method depends
  on a limited set of RGB views to perceive the 3D surroundings containing transparent
  and specular objects and achieve accurate grasping. Our method utilizes pre-trained
  depth prediction models to establish geometry constraints, enabling precise 3D structure
  estimation, even under limited view conditions. Finally, we integrate hash encoding
  and a proposal sampler strategy to significantly accelerate the 3D reconstruction
  process. These innovations significantly enhance the adaptability and effectiveness
  of our algorithm in real-world scenarios. Through comprehensive experimental validation,
  we demonstrate that RGBGrasp achieves remarkable success across a wide spectrum
  of object-grasping scenarios, establishing it as a promising solution for real-world
  robotic manipulation tasks. The demo of our method can be found on: https://sites.google.com/view/rgbgrasp'
tags:
- Computer Science - Robotics

links:
- name: URL
  url: http://arxiv.org/abs/2311.16592
---
